sdk-gcc

## 2018/3/10

11点11分，将样例的输出直接输出。

## 2018/3/12

今天已经过去3天了。昨天将输入输出调试成功，顺利的提交了一个baseline_0.155。

今天，感觉有很多需要优化的地方，比如在读取数据方面，之前先将char * info的数据转化为string s类型，然后将string类型赋值给stringstream ss(s)，再将ss输入流读入到相应变量。但是发现这种方式，通过clock_t start,finish测试，速度要比sscanf函数慢一倍。于是将sscanf作为读取数据的函数。

同样，文件中涉及到大量的时间处理格式，比如输入文件中的需要预测天数之间的间隔。需要将字符串的时间转换为整数，可以使用time_t类型来处理，详细的转换过程，可以参考[c/c++日期时间处理与字符串string转换](http://www.cnblogs.com/renjiashuo/p/6913668.html)这篇博客。

在读入train数据时，是可以先将vector的大小分配出来，这样避免后续总是扩展，移动而浪费时间。真是用了python，再用其他的好难受。

还有，实际上，train文件虚拟机ID以及创建时间的时分秒是不需要的，在处理时，将ID删除，将时分秒全部置换为0。

接下来，需要对input文件中的所有规格的虚拟机进行预测(注：有两种特殊情况)

- input文件中的有虚拟机，而train文件中没有出现，则对此类虚拟机预测为0,同时从最终的输出列表中删除。
- input文件中没有的虚拟机，而train文件中出现，此类不需要预测，因为题目要求：**测试用例输入的虚拟机规格通常只是历史数据的一部分,不是全部,参赛者只需要对输入的虚拟机规格进行预测即可,其他虚拟机规格无需考虑。**

接下来，对train文件的处理，因为已经将文件保存为vector<Train>的数据形式，而后面需要将每一种类型的虚拟机单独预测处理。

## 2018/3/13

昨天写的一个均值预测，加上FirstFit算法，在本地文件上测试，没有任何问题，但是一提交上去，就报错"answer exit abnormal Missing output file."。也没找出来是原因。

在本地又单步调试了很久，其中一个可能的原因是，如果预测的时间开始是2015-02-20 00:00:00，结束是2015-02-27 23:59:59。本地算法会将时间计算为0天，因此，再最后进行改进，如果时间为0天，则需要加上一天。但是提交后依然爆出相同的错误。

接下来，从两个方面进行排查。

- 预测的地方出错，先写一个简单的预测算法，看看装箱部分是否出错。
- 装箱的地方出错，使用一个虚拟机分配一个服务器的方法，看看是否是装箱出错。

这样线上调试，真是麻烦，没有本地测试各个函数，感觉很是费劲。。。

经过艰难的调试，用均值预测，加上使用一个虚拟机分配一个服务器的方法,终于测通，还是说明是在装箱的地方出现了问题。

接下来，对昨天写的装箱部分进行调试，看看是什么情况。

## 2018/3/14

昨天，调试到晚上快12点，终于把问题解决了。原因是input文件的服务器内存是以G为单位，而虚拟机是以M为单位，在本地测试时，我看给的服务器内存怎么这么小，就手动改大了点，然后本地测试不会出现什么问题。但是，一提交上去测试就没有比服务器内存小的虚拟机，所以一直运行异常。

这个错误调的很心累，还是审题没看清楚。如果，不是每天有100次的机会，我可能要与本次大赛ByeBye了。最后，一条语句，一条语句的上传，看看是哪里的问题，定位到问题后，又去看了下文档，解决了问题。没有单元测试，可能这就是每天给100次的意义吧。。。

PS：昨天下午5点左右，真是累得不行，总是出错。然后看了一会“神秘巨星”，之后陪女友去逛逛街，又跑去吃了“天一花甲粉”，还是那么好吃。

回去，大概10点，又开始了尝试，近2个小时解决。也是一次很深刻的教训吧。

## 2018/3/17

前两天写了两天的小论文，今天上午又在图书馆复习机器学习。下午终于可以开撸了。

通过研究测评分数发现，预测大值比预测小值会得到更高的分数。

对于devCloud.PredictAllVM()函数而言：

- 原来分数：61.619
- 放大1.2 倍：65.277
- 放大1.5 倍：72.61
- 放大1.9 倍：75.612
- 放大2   倍：77.084
- 放大2.1 倍：75.462
- 放大2.2 倍：75.036
- 放大2.5 倍：71.858

对于devCloud.LastPredictDay()函数而言：

- 原来分数：79.91
- 放大0.9倍：78.554
- 放大1.1倍：83.093
- 放大1.2倍：83.896
- 放大1.3倍：82.822
- 放大1.5倍：76.846
- 放大2.0倍：

发现，对预测的天数的总量加减也会有影响，同对devCloud.LastPredictDay()函数而言，预测结果放大1.2倍。

- 多预测一天：76.726
- 少预测一天：84.397
- 少预测两天：80.207

这就很有意思，通过后处理的组合，会极大的提高分数。但是，这是建立在有个好的算法的基础上进行微调。

## 2018/3/18

想到对于资源优化来讲，其实，如果资源利用率小于一个阈值(比如小于50%)，可以将该服务器再放入适合的同种的虚拟机来提高资源利用率，这样一来资源利用率有所提高，同时，预测大值相同有利，分数应该会有所提升，至于阈值的大小，可以测试到一个合适的比例。

下午实现了一个规则预测，还有很多值得优化的地方。

- 原始分数为：78.899
- 放大1.1 倍：82.512
- 放大1.15倍：85.024
- 放大1.2 倍：86.899
- 放大1.25倍：86.508
- 放大1.5 倍：81.331

## 2018/3/20

实现了BestFit，但是分数并没有提高。

检查了一下利用率，发现确实有一箱的利用率低于50%.

- 原始分数为：78.899
- 用最前面的装最大，提高到82.685，说明有一定的效果
- GuiZe乘以1.2后，在提高，分数反而下降，从86.899下降到86.362，说明一味的提身有风险的。

每个提升一个看看效果：

- 分数反而下降：79.125
- 乘以1.2后，再提高，分数有所提高了：87.104
- 乘以1.2后，对利用率小于70的再提高，分数有所提高了：87.252

## 2018/03/24

用python对给的样本数据进行分析之后，发现并没有明显的可以学习的周期趋势，而且训练样本不太多，使用复杂的模型必定容易过拟合。因此，还是需要在规则的基础上进行改进。

通过观察数据发现，所有虚拟机的当天总量有着明显的波动周期，但是对应每个单独的虚拟机而言，有的有着明显的周期规律，而有的总量比较小，总数在10以下，甚至5以下，基本就没有规则可言。

针对上述的问题，想到对虚拟机根据总量来进行分类，总量大的用规则去学习，而总量小的，可以直接用过去的总量来代替未来的总量。总量的分界值可以依靠线上的效果来确定。

- 暂定方案为该类型的虚拟机如果选择的训练天数n不大于等于n天的总量m，则判定为少量使用类型。
- 反之，如果训练天数n大于等于n天的的总量m，则判定为大量使用类型，至于此类的还需不需要划分，需要再观察。

使用ClassificationPredict()来进行预测，结果居然和GuiZe()的分数一样，但是测试到两种方法都使用了。这就说明对于用的少的样本来讲，使用GuiZe()和使用LastPredictDay()效果相同。

这样，此分类以失败而告终。

尝试一下融合的方案，分类还要继续研究下去。

使用GuiZe()和LastPredictDay()的最好结果进行融合：

- 对上面两种预测的结果各自乘以1.2，再按0.6与0.4加权，分数为85.41
- 对上面两种预测的结果各自乘以1.2，再按0.5与0.5加权，分数为85.297
- 对上面两种预测的结果各自乘以1.2，再按0.65与0.35加权，分数为85.639
- 对上面两种预测的结果各自乘以1.2，再按0.7与0.3加权，分数为85.639

- 对上面两种预测的结果按0.6与0.4加权，分数为77.467
- 对上面两种预测的结果按0.6与0.4加权，再对结果乘以1.2，分数为85.328
- 对上面两种预测的结果按0.5与0.5加权，再对结果乘以1.2，分数为85.232

再次失败，分析可能原因是，此两种方法本质有很大的相似性，并不能够取得异质的效果。

## 2018/03/31

更换了新测评方法后，使用规则方法得分为71.203，预测结果乘以1.2后的预测分数为78.376。

开始对异常值进行处理，使用四分位数的方法。

- 对K = 1.5，大于估计最大值的按最大值给。没乘1.2的分数为：72.62。
- 对K = 3，大于估计最大值的按最大值给。没乘1.2的分数为：73.059。
- 对K = 1.5，大于估计最大值的按最大值给。乘1.2的分数为：78.179。此分数反而下降了。
- 对K = 3，大于估计最大值的按最大值给。乘1.2的分数为：81.282。

- 对K = 1.5，大于估计最大值的按0.8给。乘1.2的分数为：78.058。
- 对K = 3，大于估计最大值的按0.8给。乘1.2的分数为：79.355。
- 对K = 1.5，大于估计最大值的按0.7给。乘1.2的分数为：77.964。
- 对K = 3，大于估计最大值的按0.7给。乘1.2的分数为：79.383。

## 2018/04/03

实现了背包方法，但是和BestFit的效果一样。应该是现在的flavor用例较少，没有体现出来优势。

再对GuiZe()进行改进，之前使用factor_median作为因子，现在尝试用factor_mean，后续可能组合这两个因子。

## 2018/04/07

上午尝试把每个没装满的服务器，装该服务器里已有的虚拟机的类型，直到装满为止。结果效果不错，最高成绩到83.252。将一些利用率小于70%的服务器删除，也能提高分数，最高到82.256。

现在没有其他的办法了，尝试使用线性回归的方法来处理一下。

线性回归在本地测试要比规则高一些，但是线上却不行。

- 原始分数：69.761
- 乘以1.2倍之后：76.513，再次基础上提高利用率得77.846。使用30天的数据得分为75.393。
- 不处理异常值，乘以1.2得分为：74.77。

## 2018/04/08

今天继续对线性回归进行改进。

- 直接用最后三次的，按0.6/0.3/0.2比例处理，能够上80.439
- 修复了两处bug，一处在LinearRegression()里，少算了最近的一次总和。一处在DongTai()，在要不要加上第一个问题上，多加一个判断。
- 修改后，用最后10次的加权，分数为：75.124。乘以1.2之后的分数为：76.889。
- 对这10次处理异常值，之后得分为75.124：。乘以1.2之后的得分为：76.889。

- 使用最后30次的加权，分数为64.93：。乘以1.2之后的分数为：72.326。


## 2018/04/11

先线上进行训练，实现线性回归线上训练的方法。

- 对每一种虚拟机单独进行训练，效果不好。
- 尝试将所有种类的虚拟机放在一起训练，每种选择m = 10个样本，特征选择 n = 3, 线上分数为76.783。
- 每种选择m=10个样本，特征选择n=5,线上分数为76.004。
- 每种选则m=21个样本，特征选择n=5,线上分数为72.752。

加上L2正则项试试，取lambda = 1.0

- 每种选择m=10个样本，特征选择n=3,线上分数为。
- 每种选择m=10个样本，特征选择n=5,线上分数为75.793。
- 每种选则m=21个样本，特征选择n=5,线上分数为。

## 2018/04/12

实现一个指数回归算法，一次指数效果74.905来分。

让动态规划跑一千次，选择分配最优的一次，但是分数没有提升。

## 2018/04/13

最后一天了，尝试一下，几种方法的基本分数。

GuiZe()的分数

- 使用中位数做因子，最后3天做base，得分为71.786。
- 使用中位数做因子，最后3天做base，乘以1.2以后，得分为67.35。看来，不是任何时候都可以放大滴。
- 使用中位数做因子，最后3天做base，乘以1.1后，得分为69.281.
- 使用中位数做因子，最后3天做base，除以1.1后，得分为72.403.
- 使用中位数做因子，最后3天做base，除以1.2后，得分为74.283.在此基础上提高利用率分数到75.018。将利用率低的删去能够到75.127。
- 使用中位数做因子，最后3天做base，除以1.3后，得分为71.222.

- 使用中位数做因子，最后5天做base，得分为79.236。在此基础上把所有的服务器装满，分数到80.627；在此基础上把利用率小于70%的装满，得分为79.977；先把小的删除，再把整体装满，得分为80.978.
- 使用中位数做因子，最后5天做base，乘以1.1之后得分为78.065
- 使用中位数做因子，最后5天做base，乘以1.2之后得分为77.888
- 使用中位数做因子，最后5天做base，除以1.1之后得分为71.518

- 使用使用中位数做因子，最后7天做base，得分为73.059.
- 使用使用中位数做因子，最后7天做base，结果乘以1.2，得分为81.282.在此基础上把利用率低的删除，利用率高的提高，得分为：82.731；在此基础上把所有利用率都提高，分数为83.252。

- 使用使用均值做因子，最后7天做base，得分为76.745.
- 使用使用均值做因子，最后7天做base，乘以1.2得分为80.649。在此基础上所有提高利用率，得分为81.635；利用率低的删除，高的放满，得分为84.783。

- 使用均值做因子，最后5天做base，得分为78.384。
- 使用均值做因子，最后5天做base，乘以1.1得分为79.439。在此基础上，提高所有利用率，得分为80.044；利用率低的删除，高的放满，得分为82.062。
- 使用均值做因子，最后5天做base，乘以1.2得分为77.27。

- 使用均值做因子，最后3天做base，得分为70.011.
- 使用均值做因子，最后3天做base，乘以1.1得分为69.421.
- 使用均值做因子，最后3天做base，除以1.1得分为72.152.
- 使用均值做因子，最后3天做base，除以1.2得分为72.176.

对均值和中位数进行融合。

- 最后3天做base，均值0.5，中位数0.5融合，得分为：70.035.
- 最后3天做base，均值0.5，中位数0.5融合，结果乘以1.2的得分为：66.72
- 最后3天做base，均值0.5，中位数0.5融合，结果除以1.1的得分为：72.122
- 最后3天做base，均值0.5，中位数0.5融合，结果除以1.2的得分为：74.287.在此基础上，进行全部提升得75.414；在此基础上，利用率低的舍去，高的提升得分为：76.949
- 最后3天做base，均值0.5，中位数0.5融合，结果除以1.3的得分为：72.405

- 最后5天做base，均值0.5，中位数0.5融合，得分为：78.065.
- 最后5天做base，均值0.5，中位数0.5融合，乘以1.1得分为：78.546
- 最后5天做base，均值0.5，中位数0.5融合，乘以1.2得分为：80.22。在此基础上进行全部提升得分为80.817；删除再增大的得分为：80.817。
- 最后5天做base，均值0.5，中位数0.5融合，乘以1.3得分为：76.636

- 最后7天做base，均值0.5，中位数0.5融合，得分为：73.277.
- 最后7天做base，均值0.5，中位数0.5融合，乘以1.2得分为：81.335.在此基础上进行全部提升得分为82.379；删除再增大的得分为：84.852
- 最后7天做base，均值0.5，中位数0.5融合，乘以1.25得分为：78.78.

#2018/04/14

提交记录

- 使用最后5天做base，使用中位数做因子，得分为224.533，乘以1.1得分为223.751
- 还有4次机会
- 使用最后7天做base，使用中位数做因子，得分为222.275，乘以1.2得分为236.572
- 还有2次机会
- 使用最后7天做base，使用中位数做因子，得分为222.275，乘以1.2得分为236.572。在此基础上提高所有的装箱率，得分为240.762；在此基础上对装箱率低的删除，高的提升得分为：245.014
- 今天5次机会用完。


	




## 报错总结

- "the number of the placement host is zero. "
- "answer exit abnormal Missing output file."。看说明是因为程序运行中出现异常，运行失败。
- "the number of predicated flavor total number is NOT match with sum of each of predicated flavor in the Output file."
- "the number of predicated flavor total number is NOT match with actual placed flavor number"
- "there are NOT enough resource in the host"
- "The format of the output file is invalid! Error info: The sum of each flavor number is invalid (not integer)!"
- "The total number of predicted flavors is not equal to the sum of each predicted flavor number!"

